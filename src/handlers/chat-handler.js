import pollinationsAPI from '../services/pollinations-api.js';
import { getUserSession, addMessageToConversation, getConversation, clearConversation } from '../utils/session.js';

/**
 * Handle /chat command
 * @param {Object} ctx - Telegram context
 */
async function handleChat(ctx) {
  try {
    // Extract message from text (remove '/chat' or '/chat@BotName' from the beginning)
    const message = ctx.message.text.replace(/^\/chat(@\w+)?(\s+)?/i, '').trim();
    
    if (!message) {
      await ctx.reply('Please provide a message for the AI.\n\nExample: /chat Tell me about artificial intelligence');
      return;
    }
    
    // Get user settings and conversation
    const userId = ctx.from.id.toString();
    const settings = getUserSession(userId);
    const conversation = getConversation(userId);
    
    // Send "thinking" message
    const statusMsg = await ctx.reply('ğŸ¤” Thinking...');
    
    // Add user message to conversation
    const userMessage = { role: 'user', content: message };
    addMessageToConversation(userId, userMessage);
    
    // Prepare messages for API call
    const messages = [
      { role: 'system', content: 'You are a helpful, friendly AI assistant named Pollinations Bot.' },
      ...conversation
    ];
    
    // Generate text using Pollinations API
    const chatOptions = {
      model: settings.textModel,
      private: settings.privateModeEnabled
    };
    
    const response = await pollinationsAPI.generateText(messages, chatOptions);
    
    // Add AI response to conversation
    const aiMessage = { role: 'assistant', content: response };
    addMessageToConversation(userId, aiMessage);
    
    // Send response to user
    await ctx.reply(response, { parse_mode: 'Markdown' });
    
    // Delete the "thinking" message
    await ctx.api.deleteMessage(ctx.chat.id, statusMsg.message_id);
    
  } catch (error) {
    console.error('Error in chat handler:', error);
    await ctx.reply(`âš ï¸ Error generating response: ${error.message || 'Unknown error'}`);
  }
}

/**
 * Handle /clearchat command
 * @param {Object} ctx - Telegram context
 */
async function handleClearChat(ctx) {
  // æ­¤å‡½æ•°ç”±grammyçš„å‘½ä»¤å¤„ç†å™¨è°ƒç”¨ï¼Œæ— éœ€é¢å¤–æ£€æŸ¥
  const userId = ctx.from.id.toString();
  clearConversation(userId);
  await ctx.reply('ğŸ§¹ Conversation history cleared.');
}

/**
 * Handle /textmodels command
 * @param {Object} ctx - Telegram context
 */
async function handleTextModels(ctx) {
  try {
    console.log('å¤„ç†æ–‡æœ¬æ¨¡å‹å‘½ä»¤:', ctx.message ? ctx.message.text : 'æ— æ¶ˆæ¯æ–‡æœ¬', 'æ¥è‡ªç”¨æˆ·:', ctx.from.id);
    
    // Send "fetching" message
    const statusMsg = await ctx.reply('Fetching available text models...');
    
    // Get available models from Pollinations API
    const models = await pollinationsAPI.listTextModels();
    
    // Filter and format text models (exclude audio models)
    const textModels = models
      .filter(model => model?.type === 'text' || !model?.type)
      .map(model => `â€¢ ${model.model || model}`);
    
    const response = `*Available Text Models:*\n\n${textModels.join('\n')}\n\nUse /settings to change your default model.`;
    
    // Send models list to user
    await ctx.reply(response, { parse_mode: 'Markdown' });
    
    // Delete the "fetching" message
    await ctx.api.deleteMessage(ctx.chat.id, statusMsg.message_id);
    
  } catch (error) {
    console.error('Error fetching text models:', error);
    await ctx.reply(`âš ï¸ Error fetching text models: ${error.message || 'Unknown error'}`);
  }
}

/**
 * Handle /models command (general)
 * @param {Object} ctx - Telegram context
 */
async function handleModels(ctx) {
  try {
    console.log('å¤„ç†æ¨¡å‹åˆ—è¡¨å‘½ä»¤:', ctx.message ? ctx.message.text : 'æ— æ¶ˆæ¯æ–‡æœ¬', 'æ¥è‡ªç”¨æˆ·:', ctx.from.id);
    
    // Send "fetching" message
    const statusMsg = await ctx.reply('æ­£åœ¨è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨...');
    
    // Get all models in parallel
    const [textModels, imageModels] = await Promise.all([
      pollinationsAPI.listTextModels(),
      pollinationsAPI.listImageModels()
    ]);
    
    // æŒ‰ç±»å‹è¿‡æ»¤æ¨¡å‹
    const textOnlyModels = textModels
      .filter(model => model.type === 'text')
      .map(model => {
        let modelInfo = `â€¢ ${model.model}`;
        if (model.description) {
          modelInfo += ` - ${model.description}`;
        }
        
        // æ·»åŠ æ¨¡å‹ç‰¹æ€§æ ‡è®°
        if (model.vision) modelInfo += ' [æ”¯æŒå›¾åƒ ğŸ‘ï¸]';
        if (model.reasoning) modelInfo += ' [é«˜çº§æ¨ç† ğŸ¤”]';
        
        return modelInfo;
      });
      
    const audioModels = textModels
      .filter(model => model.type === 'audio')
      .map(model => {
        let modelInfo = `â€¢ ${model.model}`;
        if (model.description) {
          modelInfo += ` - ${model.description}`;
        }
        
        // æ·»åŠ æ”¯æŒçš„å£°éŸ³æ•°é‡
        if (model.voices && model.voices.length) {
          modelInfo += ` [${model.voices.length} ä¸ªå£°éŸ³]`;
        }
        
        return modelInfo;
      });
    
    const imageModelsList = imageModels.map(model => `â€¢ ${model}`);
    
    // Construct response
    let response = '*å¯ç”¨æ¨¡å‹åˆ—è¡¨:*\n\n';
    
    if (textOnlyModels.length) {
      response += '*æ–‡æœ¬æ¨¡å‹:*\n' + textOnlyModels.join('\n') + '\n\n';
    }
    
    if (imageModelsList.length) {
      response += '*å›¾åƒæ¨¡å‹:*\n' + imageModelsList.join('\n') + '\n\n';
    }
    
    if (audioModels.length) {
      response += '*éŸ³é¢‘æ¨¡å‹:*\n' + audioModels.join('\n') + '\n\n';
    }
    
    response += 'ä½¿ç”¨ /settings æ›´æ”¹æ‚¨çš„é»˜è®¤æ¨¡å‹è®¾ç½®ã€‚';
    
    // Send models list to user
    await ctx.reply(response, { parse_mode: 'Markdown' });
    
    // Delete the "fetching" message
    await ctx.api.deleteMessage(ctx.chat.id, statusMsg.message_id);
    
  } catch (error) {
    console.error('Error fetching models:', error);
    await ctx.reply(`âš ï¸ è·å–æ¨¡å‹åˆ—è¡¨é”™è¯¯: ${error.message || 'æœªçŸ¥é”™è¯¯'}`);
  }
}

export default {
  handleChat,
  handleClearChat,
  handleTextModels,
  handleModels
}; 